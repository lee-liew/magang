{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import glob\n",
    "import pandas as pd\n",
    "from itertools import islice  \n",
    "import xgboost as xgb\n",
    "from model_config import *\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from scipy import stats\n",
    "from sklearn.metrics import r2_score, explained_variance_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from treesbo.tuning import main_tuning_with_bo\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-meditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lblrtm_tape11_reader(fname, opt):\n",
    "    #%[波数，光学厚度]\n",
    "    #% File format illustration\n",
    "    #% for single precision\n",
    "    #% shift 266*4 bytes\n",
    "    #% LOOP\n",
    "    #% 1 int        , 24 (block of v1, v2, dv, npts)\n",
    "    #% 2 double vars, for v1, and v2\n",
    "    #% 1 float      , for dv\n",
    "    #% 1 int        , for npts\n",
    "    #% 1 int        , 24\n",
    "    #% 1 int        , 9600 or npts*4 (beg of block output)\n",
    "    #% NPTs float   , rad\n",
    "    #% 1 int        , 9600 or npts*4 (end of block of output)\n",
    "    #% LOOP ENDS\n",
    "    #\n",
    "    #% for double precision\n",
    "    #% shift 356*4 bytes\n",
    "    #% LOOP\n",
    "    #% 1 int        , 32 (v1, v2, dv and npts, extra 0)\n",
    "    #% 3 double vars, for v1, v2, and dv\n",
    "    #% 1 long int   , for npts\n",
    "    #% 1 int        , 32   \n",
    "    #% 1 int        , 19200 or npts*8 (beg of block of output)\n",
    "    #% NPTS double  , rad\n",
    "    #% 1 int        , 19200 or npts*8 (end of block of output)\n",
    "    #% LOOP ENDS\n",
    "    #%npts: the number of points in the panel?\n",
    "    #% Author: Xianglei Huang\n",
    "    #% Tested on Redhat Linux with pgi-compiler version of LBLRTM\n",
    "    v = np.array([])\n",
    "    rad = np.array([])\n",
    "    if opt.lower() == 'float' or opt.lower() == 'single':\n",
    "        shift = 266\n",
    "        itype   = 1\n",
    "    else:\n",
    "        shift = 356\n",
    "        itype = 2\n",
    "    #print(shift,itype)\n",
    "    fid = open(fname, 'rb')\n",
    "    fid.seek(shift*4)\n",
    "    #% decide whether need to open as big-endian file\n",
    "    test = struct.unpack(\"i\",fid.read(4))[0]  #matlab中的'int'对应c的'int'\n",
    "    #print(\"test=\",test)\n",
    "    fid.close()\n",
    "    if (itype == 1 and test == 24) or (itype ==2 and test == 32):\n",
    "        fid = open(fname, 'rb')\n",
    "        fid.seek(shift*4)\n",
    "        order='<'\n",
    "    else:\n",
    "        fid = open(fname, 'rb')\n",
    "        fid.seek(shift*4)\n",
    "        order='>'        \n",
    "    #print(order)\n",
    "    endflg = 0\n",
    "    panel = 0\n",
    "#\n",
    "    if itype == 1:   \n",
    "        while endflg == 0:\n",
    "            panel = panel + 1\n",
    "            _ = struct.unpack(order+\"i\",fid.read(4))[0]\n",
    "            v1= struct.unpack(order+\"d\",fid.read(8))[0]#matlab的'double'对应c的'double'，对应python的float，占8字节\n",
    "            #print(\"v1=\",v1)\n",
    "            if np.isnan(v1):\n",
    "                break\n",
    "            v2= struct.unpack(order+\"d\",fid.read(8))[0]\n",
    "            #print(\"v2=\",v2)\n",
    "            dv= struct.unpack(order+\"f\",fid.read(4))[0]#matlab的'float'对应c的'float'，对应python的float，占4字节\n",
    "            #print(\"dv=\",dv)\n",
    "            npts= struct.unpack(order+\"i\",fid.read(4))[0]\n",
    "            #print(\"npts=\",npts)\n",
    "            if npts!=2400:\n",
    "                endflg=1\n",
    "                #print(\"npts break\",\" and npts=\",npts)\n",
    "            _ = struct.unpack(order+\"i\",fid.read(4))[0]\n",
    "            LEN= struct.unpack(order+\"i\",fid.read(4))[0]\n",
    "            if LEN!=4*npts:\n",
    "                #print('1 internal file inconsistency')\n",
    "                endflg=1\n",
    "            tmp= struct.unpack(order+str(npts)+\"f\",fid.read(4*npts))\n",
    "            #print(\"tmp=\",tmp)\n",
    "            LEN2= struct.unpack(order+\"i\",fid.read(4))[0]\n",
    "            if LEN != LEN2:\n",
    "                #print('2 internal file inconsistency')\n",
    "                endflg=1\n",
    "            v=np.append(v,np.arange(v1,v2,dv).transpose())\n",
    "            rad=np.append(rad,np.array(tmp).reshape(npts,1))\n",
    "    else:\n",
    "        print(\"itype != 1\")\n",
    "        while endflg == 0:\n",
    "            panel = panel + 1\n",
    "            _ = struct.unpack(order+\"i\",fid.read(4))[0]\n",
    "            tmp= struct.unpack(order+\"3d\",fid.read(8*3))\n",
    "            v1=tmp[0]\n",
    "            v2=tmp[1]\n",
    "            dv=tmp[2]\n",
    "            if np.isnan(v1):\n",
    "                break \n",
    "            npts= struct.unpack(order+\"q\",fid.read(8))[0] #npts = fread(fid, 1, 'int64');\n",
    "            if npts!=2400:\n",
    "                endflg=1\n",
    "                #print(\"npts break\")\n",
    "            _ = struct.unpack(order+\"i\",fid.read(4))[0]   \n",
    "            LEN= struct.unpack(order+\"i\",fid.read(4))[0]\n",
    "            if LEN!=8*npts:\n",
    "                #print('3 internal file inconsistency')\n",
    "                endflg=1\n",
    "            tmp= struct.unpack((order+str(npts)+\"d\"),fid.read(8*npts))\n",
    "            LEN2= struct.unpack(order+\"i\",fid.read(4))[0]\n",
    "            if LEN != LEN2:\n",
    "                #print('4 internal file inconsistency')\n",
    "                endflg=1\n",
    "            v=np.append(v,np.arange(v1,v2,dv).transpose())\n",
    "            rad=np.append(rad,np.array(tmp).reshape(npts,1))                \n",
    "    fid.close()\n",
    "    return v,rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-wages",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EC(fname):\n",
    "    p=np.array([])\n",
    "    t=np.array([])\n",
    "    wv=np.array([])\n",
    "    co2=np.array([])\n",
    "    o3=np.array([])\n",
    "    no2=np.array([])\n",
    "    co=np.array([])\n",
    "    ch4=np.array([])\n",
    "    input_file=open(fname)\n",
    "    num=0\n",
    "    for line in islice(input_file,19,None):\n",
    "        num=num+1\n",
    "        #print(line)\n",
    "        p_temp,t_temp,wv_temp,co2_temp,o3_temp,no2_temp,co_temp,ch4_temp=[float(i) for i in line.split()]\n",
    "        p=np.append(p,p_temp)\n",
    "        t=np.append(t,t_temp)\n",
    "        wv=np.append(wv,wv_temp)\n",
    "        co2=np.append(co2,co2_temp)\n",
    "        o3=np.append(o3,o3_temp)\n",
    "        no2=np.append(no2,no2_temp)\n",
    "        co=np.append(co,co_temp)\n",
    "        ch4=np.append(ch4,ch4_temp)\n",
    "        if num%101==0:\n",
    "            for line2 in islice(input_file, 0, 2):\n",
    "                continue\n",
    "            \n",
    "    return p,t,wv,co2,o3,no2,co,ch4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_evaluation(y_real, y_pred, verbose=True):\n",
    "    \"\"\"\n",
    "    y_real: real values\n",
    "    y_pred: prediction values\n",
    "    MAKE THEM HAVE THE SHAPE OF (N,) FIRST BY USING ndarray.ravel()\n",
    "    \"\"\"\n",
    "    if not isinstance(y_real, np.ndarray):\n",
    "        y_real = np.array(y_real)\n",
    "    if not isinstance(y_pred, np.ndarray):\n",
    "        y_pred = np.array(y_pred)\n",
    "    y_real = y_real.ravel()\n",
    "    y_pred = y_pred.ravel()\n",
    "\n",
    "    # MAPE\n",
    "    def cal_mape(y_true, y_pred):\n",
    "        y_true = np.where(y_true == 0, 1, y_true)  # To avoid zeros.\n",
    "        mape = np.mean(abs((y_true.ravel() - y_pred.ravel()) / y_true.ravel()))\n",
    "        return mape\n",
    "\n",
    "    m0 = stats.pearsonr(y_real, y_pred)[0]\n",
    "    m1 = r2_score(y_real, y_pred)\n",
    "    m2 = explained_variance_score(y_real, y_pred)\n",
    "    m3 = mean_squared_error(y_real, y_pred)\n",
    "    m4 = mean_absolute_error(y_real, y_pred)\n",
    "    m5 = cal_mape(y_real, y_pred)\n",
    "    if verbose:\n",
    "        print(\"模型的评估结果:\")\n",
    "        print(\n",
    "            'PersonR: %f \\nRMSE: %f \\nR2: %f \\nExplained Variance: %f \\nMSE: %f \\nMAE: %f \\nMAPE: %f'\n",
    "            % (m0, np.sqrt(m3), m1, m2, m3, m4, m5))\n",
    "    return m0, np.sqrt(m3), m1, m2, m3, m4, m5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-auditor",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecpath='/mnt/hdd2/228_data/liuli/liul'\n",
    "ozopath='/mnt/hdd2/228_data/liuli/liul/ozo/angle1'\n",
    "ec_name=ecpath+'/ECMWF_83P_101L.dat'\n",
    "#print(type(test_name))\n",
    "p,t,wv,co2,o3,no2,co,ch4=EC(ec_name)   \n",
    "#print(t)\n",
    "ec_input=np.hstack((p.reshape(-1,1),t.reshape(-1,1),wv.reshape(-1,1),co2.reshape(-1,1),o3.reshape(-1,1),no2.reshape(-1,1),co.reshape(-1,1),ch4.reshape(-1,1)))\n",
    "print(ec_input.shape)\n",
    "ec_input_100=np.zeros((83*100,ec_input.shape[1]))\n",
    "for pro in range(0,83): #83条\n",
    "    for i in range(0+101*pro,100+101*pro):\n",
    "        for j in range(ec_input.shape[1]):\n",
    "            ec_input_100[i-101*pro+100*pro,j]=(ec_input[i,j]+ec_input[i+1,j])/2.0\n",
    "print(ec_input_100.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#把EC83的廓线按照第一条，第一层复制55万个，然后第二条、第一层，共83*100*55万个数据。\n",
    "ec_df=pd.DataFrame(ec_input_100)\n",
    "#print(ec_df)\n",
    "\n",
    "true_total=np.array([])\n",
    "pre_total=np.array([])\n",
    "for i in range(99,-1,-1):\n",
    "    f = open(\"metrics_%d.txt\" %(i), \"w\")\n",
    "    tot=np.array([])\n",
    "    v=np.array([])\n",
    "    mg_od=np.array([])\n",
    "    for pro in range(0,83):\n",
    "     #倒叙原因是为与ozo文件统一，ozo中第一层是最底层\n",
    "        new=np.repeat(ec_df.iloc[i+pro*100].values.reshape(1,-1),555001,axis=0)\n",
    "        #print(new.shape)\n",
    "        tot=np.append(tot,new)\n",
    "        lev=100-i\n",
    "        #####开始处理ozo的小文件\n",
    "        fix_name = glob.glob(ozopath+'/*_%dP_*%03d' %(pro+1,lev))\n",
    "        if os.path.exists(fix_name[0]):\n",
    "            v_temp,mg_od_temp = lblrtm_tape11_reader(fix_name[0],'single')\n",
    "            mg_od_temp=np.exp(-mg_od_temp)\n",
    "            #print(\"小文件测试\",v_temp.shape,mg_od_temp.shape)\n",
    "            #print(np.where(mg_od_temp==np.max(mg_od_temp)))\n",
    "            #print(v_temp[22515])\n",
    "            #fig = plt.figure(figsize=(15,10))\n",
    "            #ax1 = fig.add_subplot(211)         \n",
    "            #l1,=ax1.plot(v_temp,mg_od_temp,'g-',linewidth=1.5)\n",
    "            #ax2 = fig.add_subplot(212)\n",
    "            #l2,=ax2.plot(mg_od_temp,'r:', linewidth=1.5)\n",
    "            #plt.show()            \n",
    "        else:\n",
    "            v_temp=np.full([555001,], np.nan)\n",
    "            mg_od_temp=np.full([555001,], np.nan)\n",
    "        v=np.append(v,v_temp)\n",
    "        mg_od=np.append(mg_od,mg_od_temp)\n",
    "    tot=tot.reshape(-1,8)\n",
    "    v=v.reshape(-1,1)\n",
    "    \n",
    "    mg_od=mg_od.reshape(-1,1)\n",
    "    \n",
    "    #print(tot.shape)\n",
    "    X=np.hstack((tot,v))\n",
    "    #print(X.shape)\n",
    "    #print(X)\n",
    "    Y=mg_od\n",
    "    \n",
    "    #print(Y)\n",
    "    print(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    f.write(\"start：\"+datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')+\"\\n\")\n",
    "    #########开始训练并比较结果\n",
    "    print(\"####################！！！LGB Running！！！##########################\")\n",
    "    #best_params, loss=main_tuning_with_bo(\n",
    "    #X_train=X[:60*555001],\n",
    "    #y_train=Y[:60*555001].ravel(),\n",
    "    #X_val=X[60*555001:],\n",
    "    #y_val=Y[60*555001:].ravel(),\n",
    "    #model_nm='LGB',\n",
    "    #max_evals=3,\n",
    "    #folds=None,\n",
    "    #nfold=3,\n",
    "    #eval_metric='l1',\n",
    "    #task='regression')\n",
    "    #print(best_params,loss)\n",
    "    model2 = lgb.LGBMRegressor(**lgbm_params)\n",
    "    model2.fit(X[:60*555001], Y[:60*555001].ravel())\n",
    "    #model2 = lgb.LGBMRegressor()\n",
    "    #gs2 = GridSearchCV(model2, lgbm_grid, cv=3, n_jobs=-1)\n",
    "    #gs2.fit(X[:60*555001], Y[:60*555001].ravel())\n",
    "    #print(gs2.best_params_)\n",
    "    #print(gs2.best_score_)\n",
    "    #best_model2=gs2.best_estimator_\n",
    "    y_pred2 = model2.predict(X[60*555001:])\n",
    "    metrics_i2 = func_evaluation(Y[60*555001:], y_pred2)\n",
    "    f.write(\"LGB_finished:\"+datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')+\"\\n\")\n",
    "    f.write(str(lgbm_params))\n",
    "    f.write(str(metrics_i2)+\"\\n\")\n",
    "    joblib.dump(model2, 'model_level_%02d.pkl' %(i))\n",
    "    print(\"LGB\",metrics_i2)\n",
    "    \n",
    "    true_total=np.append(true_total,Y[60*555001:])\n",
    "    pre_total=np.append(pre_total, y_pred2)\n",
    "    #fig = plt.figure(figsize=(15,10))\n",
    "    #ax1 = fig.add_subplot(211)         \n",
    "    #l1,=ax1.plot(X[60*555001:],Y[60*555001:],'g-',linewidth=1.5)\n",
    "    #l2,=ax1.plot(X[60*555001:],y_pred2,'r:',linewidth=1.5)\n",
    "    #plt.savefig(\"OD_plot.png\",dpi=100)\n",
    "    #plt.show()\n",
    "    \n",
    "\n",
    "    #print(\"####################！！！RF Running！！！##########################\")\n",
    "    #best_params3, loss3=main_tuning_with_bo(\n",
    "    #X[:60*555001],\n",
    "    #Y[:60*555001].ravel(),\n",
    "    #model_nm='RF',\n",
    "    #max_evals=10,\n",
    "    #folds=None,\n",
    "    #nfold=3,\n",
    "    #eval_metric='l2',\n",
    "    #task='regression')\n",
    "    #print(best_params3,loss3)\n",
    "    #model3 = RandomForestRegressor(**best_params3)\n",
    "    #model3.fit(X[:60*555001], Y[:60*555001].ravel()) \n",
    "    #y_pred3 = model3.predict(X[60*555001:])\n",
    "    #metrics_i3 = func_evaluation(Y[60*555001:], y_pred3)\n",
    "    #f.write(\"RF_finished:\"+datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')+\"\\n\")\n",
    "    #f.write(str(best_params3))\n",
    "    #f.write(str(metrics_i3)+\"\\n\")\n",
    "    #print(\"RF\",metrics_i3)\n",
    "    \n",
    "#\n",
    "    #print(\"####################！！！ET Running！！！##########################\")\n",
    "    #model4 = ExtraTreesRegressor(**et_params)\n",
    "    #model4.fit(X[:60*555001], Y[:60*555001].ravel())\n",
    "    #y_pred4 = model4.predict(X[60*555001:])\n",
    "    #metrics_i4 = func_evaluation(Y[60*555001:], y_pred4)\n",
    "    #f.write(str(datetime.datetime.now())+str(metrics_i4)+\"\\n\")\n",
    "    #print(\"ET\",metrics_i4) \n",
    "    #\n",
    "#\n",
    "    #print(\"####################！！！CAT Running！！！##########################\")\n",
    "    #model5 = CatBoostRegressor(**cat_params,verbose=None)\n",
    "    #model5.fit(X[:60*555001], Y[:60*555001].ravel())\n",
    "    #y_pred5 = model5.predict(X[60*555001:])\n",
    "    #metrics_i5 = func_evaluation(Y[60*555001:], y_pred5)\n",
    "    #f.write(str(datetime.datetime.now())+str(metrics_i5)+\"\\n\")\n",
    "    #f.write(\"end\"+datetime.datetime.now()+\"\\n\")\n",
    "    #print(\"CAT\",metrics_i5) \n",
    "    #\n",
    "#\n",
    "    #print(\"####################！！！XGBoost Running！！！##########################\")\n",
    "    #model = xgb.XGBRegressor(**xgb_params)\n",
    "    #model.fit(X[:60*555001], Y[:60*555001].ravel()) ###共83条廓线，前80条做训练，后3条做测试\n",
    "    #y_pred = model.predict(X[60*555001:])\n",
    "    #metrics_i = func_evaluation(Y[60*555001:], y_pred)\n",
    "    #f.write(str(datetime.datetime.now())+str(metrics_i)+\"\\n\")\n",
    "    #print(\"XGB:\",metrics_i)\n",
    "    f.close()\n",
    "#    if i==99:\n",
    "#        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-hunger",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('pre.npz', sequence_array=pre_total)\n",
    "np.savez('tru.npz', sequence_array=true_total)\n",
    "metrics_total = func_evaluation(true_total, pre_total)\n",
    "print(metrics_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "ax1 = fig.add_subplot(211)  \n",
    "print(true_total.shape,pre_total.shape)\n",
    "print(np.mean(abs(true_total.ravel()-pre_total.ravel())))\n",
    "l1,=ax1.plot(true_total[190*555001:199*555001].ravel()-pre_total[190*555001:199*555001].ravel(),'g-',linewidth=1.5)\n",
    "plt.legend([\"bias\"])\n",
    "#plt.savefig(\"OD_plot.png\",dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
